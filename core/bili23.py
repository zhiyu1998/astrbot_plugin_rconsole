import asyncio
import os
import platform
import re
import subprocess
from urllib.parse import urlparse, parse_qs

import aiofiles
import astrbot.api.message_components as Comp
import httpx
from astrbot.api import logger
from astrbot.api.event import AstrMessageEvent
from bilibili_api import video, Credential, live, article
from bilibili_api.opus import Opus
from bilibili_api.video import VideoDownloadURLDataDetecter

from .common import delete_boring_characters, remove_files
from ..constants.bili23 import *

async def download_b_file(url, full_file_name, progress_callback):
    """
        ä¸‹è½½è§†é¢‘æ–‡ä»¶å’ŒéŸ³é¢‘æ–‡ä»¶
    :param url:
    :param full_file_name:
    :param progress_callback:
    :return:
    """
    async with httpx.AsyncClient(transport=httpx.AsyncHTTPTransport(local_address="0.0.0.0")) as client:
        async with client.stream("GET", url, headers=BILIBILI_HEADER) as resp:
            current_len = 0
            total_len = int(resp.headers.get('content-length', 0))
            print(total_len)
            async with aiofiles.open(full_file_name, "wb") as f:
                async for chunk in resp.aiter_bytes():
                    current_len += len(chunk)
                    await f.write(chunk)
                    progress_callback(f'ä¸‹è½½è¿›åº¦ï¼š{round(current_len / total_len, 3)}')


async def merge_file_to_mp4(v_full_file_name: str, a_full_file_name: str, output_file_name: str,
                            log_output: bool = False):
    """
    åˆå¹¶è§†é¢‘æ–‡ä»¶å’ŒéŸ³é¢‘æ–‡ä»¶
    :param v_full_file_name: è§†é¢‘æ–‡ä»¶è·¯å¾„
    :param a_full_file_name: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
    :param output_file_name: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    :param log_output: æ˜¯å¦æ˜¾ç¤º ffmpeg è¾“å‡ºæ—¥å¿—ï¼Œé»˜è®¤å¿½ç•¥
    :return:
    """
    logger.info(f'æ­£åœ¨åˆå¹¶ï¼š{output_file_name}')

    # æ„å»º ffmpeg å‘½ä»¤
    command = f'ffmpeg -y -i "{v_full_file_name}" -i "{a_full_file_name}" -c copy "{output_file_name}"'
    stdout = None if log_output else subprocess.DEVNULL
    stderr = None if log_output else subprocess.DEVNULL

    if platform.system() == "Windows":
        # Windows ä¸‹ä½¿ç”¨ run_in_executor
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(
            None,
            lambda: subprocess.call(command, shell=True, stdout=stdout, stderr=stderr)
        )
    else:
        # å…¶ä»–å¹³å°ä½¿ç”¨ create_subprocess_shell
        process = await asyncio.create_subprocess_shell(
            command,
            shell=True,
            stdout=stdout,
            stderr=stderr
        )
        await process.communicate()


def extra_bili_info(video_info):
    """
        æ ¼å¼åŒ–è§†é¢‘ä¿¡æ¯
    """
    video_state = video_info['stat']
    video_like, video_coin, video_favorite, video_share, video_view, video_danmaku, video_reply = video_state['like'], \
        video_state['coin'], video_state['favorite'], video_state['share'], video_state['view'], video_state['danmaku'], \
        video_state['reply']

    video_data_map = {
        "ç‚¹èµ": video_like,
        "ç¡¬å¸": video_coin,
        "æ”¶è—": video_favorite,
        "åˆ†äº«": video_share,
        "æ€»æ’­æ”¾é‡": video_view,
        "å¼¹å¹•æ•°é‡": video_danmaku,
        "è¯„è®º": video_reply
    }

    video_info_result = ""
    for key, value in video_data_map.items():
        if int(value) > 10000:
            formatted_value = f"{value / 10000:.1f}ä¸‡"
        else:
            formatted_value = value
        video_info_result += f"{key}: {formatted_value} | "

    return video_info_result


async def process_bilibili_url(event: AstrMessageEvent, credential: Credential, video_duration_maximum: int):
    """
        æ ¸å¿ƒä»£ç ï¼šå¤„ç†Bç«™é“¾æ¥
    """
    # 1. URL é¢„å¤„ç†
    # å½“å‰æ”¶åˆ°çš„æ¶ˆæ¯
    url: str = event.message_str.strip()
    url_reg = r"(http:|https:)\/\/(space|www|live|t).bilibili.com\/[A-Za-z\d._?%&+\-=\/#]*"
    b_short_rex = r"(https?://(?:b23\.tv|bili2233\.cn)/[A-Za-z\d._?%&+\-=\/#]+)"
    # BVå¤„ç†
    if re.match(r'^BV[1-9a-zA-Z]{10}$', url, re.IGNORECASE):
        url = 'https://www.bilibili.com/video/' + url
    # å¤„ç†çŸ­å·ã€å°ç¨‹åºé—®é¢˜
    if "b23.tv" in url or "bili2233.cn" in url:
        try:
            b_short_match = re.search(b_short_rex, url.replace("\\", ""))
            if not b_short_match:
                yield event.plain_result("é”™è¯¯ï¼šBç«™çŸ­é“¾æ¥è§£æå¤±è´¥ã€‚")
                return
            b_short_url = b_short_match.group(0)
            async with httpx.AsyncClient(headers=BILIBILI_HEADER, follow_redirects=True) as client:
                resp = await client.get(b_short_url)
                url: str = str(resp.url)
        except (TypeError, httpx.RequestError):
            yield event.plain_result("é”™è¯¯ï¼šBç«™çŸ­é“¾æ¥è§£æå¤±è´¥ã€‚")
            return
    # 2. æ ¹æ® URL ç±»å‹åˆ†æµå¤„ç†
    # ================== åŠ¨æ€è§£æ ==================
    if ('t.bilibili.com' in url or '/opus/' in url) and credential:
        try:
            if '?' in url:
                url = url[:url.index('?')]
            dynamic_match = re.search(r'[^/]+(?!.*/)', url)
            if not dynamic_match:
                yield event.plain_result("æ— æ³•è¯†åˆ«åŠ¨æ€IDã€‚")
                return
            dynamic_id = int(dynamic_match.group(0))
            opus = Opus(dynamic_id, credential)
            # Opus.get_content() might not be available, using get_opus_info() instead
            # Since get_opus_info() might not be available either, fallback to a more basic approach
            try:
                dynamic_info = await opus.get_info()
            except AttributeError:
                # If get_info() is not available, use a basic dictionary
                dynamic_info = { }

            # æå–å†…å®¹
            desc = ""
            user_name = "æœªçŸ¥UPä¸»"

            # å°è¯•ä¸åŒçš„æ•°æ®ç»“æ„æ ¼å¼è·å–å†…å®¹
            if 'desc' in dynamic_info and isinstance(dynamic_info['desc'], dict) and 'text' in dynamic_info['desc']:
                desc = dynamic_info['desc']['text']
            elif 'item' in dynamic_info and isinstance(dynamic_info['item'], dict) and 'description' in dynamic_info[
                'item']:
                desc = dynamic_info['item']['description']

            if 'user' in dynamic_info and isinstance(dynamic_info['user'], dict) and 'name' in dynamic_info['user']:
                user_name = dynamic_info['user']['name']
            elif 'card' in dynamic_info and isinstance(dynamic_info['card'], dict) and 'card' in dynamic_info['card']:
                card = dynamic_info['card']['card']
                if isinstance(card, dict) and 'user' in card and isinstance(card['user'], dict) and 'name' in card[
                    'user']:
                    user_name = card['user']['name']

            # æå–å›¾ç‰‡
            pics = []
            if isinstance(dynamic_info, dict):
                # å°è¯•ä¸åŒçš„æ•°æ®ç»“æ„æ ¼å¼è·å–å›¾ç‰‡
                if 'pictures' in dynamic_info and isinstance(dynamic_info['pictures'], list):
                    for p in dynamic_info['pictures']:
                        if isinstance(p, dict) and 'img_src' in p:
                            pics.append(p['img_src'])
                elif 'item' in dynamic_info and isinstance(dynamic_info['item'], dict) and 'pictures' in dynamic_info[
                    'item']:
                    for p in dynamic_info['item']['pictures']:
                        if isinstance(p, dict) and 'img_src' in p:
                            pics.append(p['img_src'])

            message_chain = [Comp.Plain(f"è¯†åˆ«åˆ°Bç«™åŠ¨æ€ (æ¥è‡ª: {user_name}):\n{desc}")]
            if pics:
                message_chain.append(Comp.Plain("\né™„å¸¦å›¾ç‰‡å¦‚ä¸‹ï¼š"))
                for pic_url in pics[:9]:  # æœ€å¤šå‘9å¼ å›¾
                    message_chain.append(Comp.Image.fromURL(pic_url))

            yield event.chain_result(message_chain)
            return
        except Exception as e:
            yield event.plain_result(f"Bç«™åŠ¨æ€è§£æå¤±è´¥: {e}")
            return
    # ================== ç›´æ’­é—´è§£æ ==================
    if 'live.bilibili.com' in url:
        try:
            room_id_match = re.search(r'\/(\d+)', url.split('?')[0])
            if not room_id_match:
                yield event.plain_result("æ— æ³•è¯†åˆ«ç›´æ’­é—´IDã€‚")
                return

            room_id = int(room_id_match.group(1))
            room = live.LiveRoom(room_display_id=room_id)
            room_info = (await room.get_room_info())['room_info']
            title, cover, keyframe = room_info['title'], room_info['cover'], room_info['keyframe']

            yield event.chain_result([
                Comp.Plain(f"è¯†åˆ«ï¼šå“”å“©å“”å“©ç›´æ’­\næ ‡é¢˜ï¼š{title}"),
                Comp.Image.fromURL(cover),
                Comp.Image.fromURL(keyframe)
            ])
            return
        except Exception as e:
            yield event.plain_result(f"Bç«™ç›´æ’­é—´è§£æå¤±è´¥: {e}")
            return

    # ================== ä¸“æ è§£æ ==================
    if '/read/cv' in url:
        try:
            cv_match = re.search(r'cv(\d+)', url)
            if not cv_match:
                yield event.plain_result("æ— æ³•è¯†åˆ«ä¸“æ IDã€‚")
                return
            read_id = cv_match.group(1)
            ar = article.Article(int(read_id), credential=credential)
            # article.get_content() might not be available, using get_info() instead
            content = await ar.get_info()
            title = content.get('title', 'æœªçŸ¥æ ‡é¢˜')

            yield event.plain_result(f"è¯†åˆ«ï¼šå“”å“©å“”å“©ä¸“æ ã€Š{title}ã€‹")
            return
        except Exception as e:
            yield event.plain_result(f"Bç«™ä¸“æ è§£æå¤±è´¥: {e}")
            return

    # ================== æ”¶è—å¤¹è§£æ (éœ€è¦SESSDATA) ==================
    if 'favlist' in url and credential:
        try:
            fid_match = re.search(r'fid=(\d+)', url)
            if not fid_match:
                yield event.plain_result("æ— æ³•è¯†åˆ«æ”¶è—å¤¹IDã€‚")
                return
            fav_id = fid_match.group(1)

            yield event.plain_result(f"è¯†åˆ«åˆ°Bç«™æ”¶è—å¤¹ID: {fav_id}ï¼Œä½†éœ€è¦å®ç°è·å–æ”¶è—å¤¹å†…å®¹çš„åŠŸèƒ½ã€‚")
            return
        except Exception as e:
            yield event.plain_result(f"Bç«™æ”¶è—å¤¹è§£æå¤±è´¥: {e} (å¯èƒ½éœ€è¦ç™»å½•å‡­æ®)")
            return

    # ================== è§†é¢‘è§£æ ==================
    # ç¡®ä¿URLæ˜¯æœ‰æ•ˆçš„è§†é¢‘é“¾æ¥
    if 'video/av' not in url and 'video/BV' not in url:
        # å¦‚æœå‰é¢çš„é€»è¾‘éƒ½æ²¡åŒ¹é…ä¸Šï¼Œå¹¶ä¸”ä¸æ˜¯è§†é¢‘é“¾æ¥ï¼Œåˆ™æ”¾å¼ƒ
        search_res = re.search(url_reg, url)
        if search_res:
            yield event.plain_result(f"å·²è¯†åˆ«é“¾æ¥ï¼Œä½†æš‚ä¸æ”¯æŒè§£ææ­¤ç±»å‹ï¼š{search_res.group(0)}")
        return
    # è·å–è§†é¢‘ä¿¡æ¯
    video_id_match = re.search(r"video\/([^\?\/ ]+)", url)
    if not video_id_match:
        yield event.plain_result("æ— æ³•ä»é“¾æ¥ä¸­æå–æœ‰æ•ˆçš„è§†é¢‘IDã€‚")
        return
    video_id = video_id_match.group(1)

    v = video.Video(video_id, credential=credential)
    video_info = await v.get_info()

    if video_info is None:
        yield event.plain_result(f"è¯†åˆ«ï¼šBç«™ï¼Œå‡ºé”™ï¼Œæ— æ³•è·å–æ•°æ®ï¼")
        return

    video_title, video_cover, video_desc, video_duration = video_info['title'], video_info['pic'], video_info[
        'desc'], \
        video_info['duration']
    # æ ¡å‡† åˆ†p çš„æƒ…å†µ
    page_num = 0
    if 'pages' in video_info:
        # è§£æURL
        parsed_url = urlparse(url)
        # æ£€æŸ¥æ˜¯å¦æœ‰æŸ¥è¯¢å­—ç¬¦ä¸²
        if parsed_url.query:
            # è§£ææŸ¥è¯¢å­—ç¬¦ä¸²ä¸­çš„å‚æ•°
            query_params = parse_qs(parsed_url.query)
            # è·å–æŒ‡å®šå‚æ•°çš„å€¼ï¼Œå¦‚æœå‚æ•°ä¸å­˜åœ¨ï¼Œåˆ™è¿”å›None
            page_num = int(query_params.get('p', [1])[0]) - 1
        else:
            page_num = 0
        if 'duration' in video_info['pages'][page_num]:
            video_duration = video_info['pages'][page_num].get('duration', video_info.get('duration'))
        else:
            # å¦‚æœç´¢å¼•è¶…å‡ºèŒƒå›´ï¼Œä½¿ç”¨ video_info['duration'] æˆ–è€…å…¶ä»–é»˜è®¤å€¼
            video_duration = video_info.get('duration', 0)
    # åˆ é™¤ç‰¹æ®Šå­—ç¬¦
    video_title = delete_boring_characters(video_title)
    # æˆªæ–­ä¸‹è½½æ—¶é—´æ¯”è¾ƒé•¿çš„è§†é¢‘
    online = await v.get_online()
    online_str = f'ğŸ„â€â™‚ï¸ æ€»å…± {online["total"]} äººåœ¨è§‚çœ‹ï¼Œ{online["count"]} äººåœ¨ç½‘é¡µç«¯è§‚çœ‹'
    # æ£€æŸ¥æ—¶é•¿
    if video_duration <= video_duration_maximum:
        yield event.chain_result([
            Comp.Image.fromURL(video_cover),
            Comp.Plain(
                f"\nè¯†åˆ«ï¼šBç«™ï¼Œ{video_title}\n{extra_bili_info(video_info)}\nğŸ“ ç®€ä»‹ï¼š{video_desc}\n{online_str}")
        ])
    else:
        yield event.chain_result([
            Comp.Image.fromURL(video_cover),
            Comp.Plain(
                f"\nè¯†åˆ«ï¼šBç«™ï¼Œ{video_title}\n{extra_bili_info(video_info)}\nç®€ä»‹ï¼š{video_desc}\n{online_str}\n---------\nâš ï¸ å½“å‰è§†é¢‘æ—¶é•¿ {video_duration // 60} åˆ†é’Ÿï¼Œè¶…è¿‡ç®¡ç†å‘˜è®¾ç½®çš„æœ€é•¿æ—¶é—´ {video_duration_maximum // 60} åˆ†é’Ÿï¼")
        ])
    # è·å–ä¸‹è½½é“¾æ¥
    download_url_data = await v.get_download_url(page_index=page_num)
    detecter = VideoDownloadURLDataDetecter(download_url_data)
    streams = detecter.detect_best_streams()
    video_url, audio_url = streams[0].url, streams[1].url
    # ä¸‹è½½è§†é¢‘å’ŒéŸ³é¢‘
    download_path = os.getcwd() + "/data/bilibili_cache/" + video_id
    os.makedirs(download_path, exist_ok=True)
    try:
        await asyncio.gather(
            download_b_file(video_url, f"{download_path}-video.m4s", logger.debug),
            download_b_file(audio_url, f"{download_path}-audio.m4s", logger.debug))
        await merge_file_to_mp4(f"{download_path}-video.m4s", f"{download_path}-audio.m4s", f"{download_path}.mp4")
    finally:
        remove_res = remove_files([f"{download_path}-video.m4s", f"{download_path}-audio.m4s"])
        logger.info(remove_res)
    # å‘é€å‡ºå»
    logger.info(f"{download_path}.mp4")
    yield event.chain_result([Comp.Video.fromFileSystem(path=f"{download_path}.mp4")])
    # AI æ€»ç»“
    if credential:
        try:
            cid = video_info['pages'][page_num]['cid']
            ai_conclusion = await v.get_ai_conclusion(cid=cid)
            if ai_conclusion and ai_conclusion.get('summary'):
                summary_text = f"ã€Bilibili AI æ€»ç»“ã€‘\n{ai_conclusion['summary']}"
                yield event.plain_result(summary_text)
        except Exception as e:
            # è·å–AIæ€»ç»“å¤±è´¥ï¼Œé™é»˜å¤„ç†
            pass
